论文复现：


1. 降低成本和资源消耗
工业界非常关注计算成本、存储成本和时间成本。如果一项技术能显著降低资源消耗，就会受到广泛欢迎。

(1) 模型微调的优化
创新点: 像 LoRA 通过引入低秩矩阵分解，避免对整个模型权重进行更新，从而大幅降低显存占用和计算成本。
实际应用:
微调一个 100B 参数的大模型通常需要数百 GB 的显存，而 LoRA 只需要更新少量参数，显存需求减少到原来的 1%。
在工业场景中，比如生成式对话系统，LoRA 可以快速部署到不同领域，而无需重新训练整个模型。
(2) 参数高效化
案例: Adapter-BERT 和 Prefix Tuning。
创新点: 只在模型中插入少量可训练参数（如 Adapter 或前缀向量），而不需要更新整个模型。
实际应用:
在多语言翻译任务中，使用 Adapter 方法为每种语言添加一个小模块，而主模型共享，显著减少存储成本。



2. 提升推理效率
在工业场景中，推理效率直接影响用户体验和服务成本。工程化创新可以通过模型压缩、加速推理等方式提升效率。

(1) 模型量化
案例: INT8/INT4 量化。
创新点: 将模型权重从 32 位浮点数压缩为 8 位或 4 位整数表示，显著减少存储和计算需求。
实际应用:
在边缘设备（如手机、IoT 设备）上部署大型模型。
比如 GPT 模型的量化版可以在消费级硬件上运行，而不影响太多性能。
(2) 模型裁剪（Pruning）
案例: Lottery Ticket Hypothesis。
创新点: 通过剪枝找到“幸运子网络”，在不显著降低性能的情况下减少模型参数。
实际应用:
剪枝后的模型在推理速度上提升了 2-3 倍，适合实时应用（如推荐系统、语音助手）。
(3) 知识蒸馏
案例: DistilBERT。
创新点: 将大型模型的知识压缩到小型模型中，保持性能的同时显著减少计算需求。
实际应用:
在工业场景中，用小型模型（如 DistilGPT）提供实时对话服务，减少延迟。
